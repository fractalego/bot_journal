{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d041322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e8380e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bcb6c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "fact_checking_model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "fact_checking_model.cuda()\n",
    "checkpoint = torch.load('save_fever_with_qa_data_13')\n",
    "fact_checking_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "_ = fact_checking_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "346a2174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_up_to_question(text):\n",
    "    _claim_yn = 'The evidence supports the claim:\\n'\n",
    "    return text[:text.find(_claim_yn) + len(_claim_yn)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34417527",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_from_text(text):\n",
    "    _claim_yn = 'The evidence supports the claim:\\n'\n",
    "    pos = text.find(_claim_yn) + len(_claim_yn)\n",
    "    return text[pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d35a241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(fact_checking_model, text):\n",
    "    prompt = get_text_up_to_question(text)\n",
    "    tokens = tokenizer.encode(prompt, return_tensors='pt')\n",
    "    _length = 1\n",
    "    tokens_length = tokens.shape[1]\n",
    "    if tokens_length + _length >= 1024:\n",
    "        raise RuntimeError('Text is longer than 1024')\n",
    "    output = fact_checking_model.generate(\n",
    "             tokens.cuda(),\n",
    "             max_length=tokens_length + _length, \n",
    "             pad_token_id=50256\n",
    "    )\n",
    "    to_return = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    perplexity = float(model(output, labels=output)[0])\n",
    "    return get_answer_from_text(to_return), perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5334aae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_answer(fact_checking_model, text):\n",
    "    prompt_y = get_text_up_to_question(text) + 'Y'\n",
    "    prompt_n = get_text_up_to_question(text) + 'N'\n",
    "    tokens_y = tokenizer.encode(prompt_y, return_tensors='pt').cuda()\n",
    "    tokens_n = tokenizer.encode(prompt_n, return_tensors='pt').cuda()\n",
    "    perplexity_y = float(model(tokens_y, labels=tokens_y)[0])\n",
    "    perplexity_n = float(model(tokens_n, labels=tokens_n)[0])\n",
    "    if perplexity_y < perplexity_n:\n",
    "        return 'Y', perplexity_y\n",
    "    return 'N', perplexity_n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d10144a",
   "metadata": {},
   "source": [
    "# Question Answering part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f16096b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_question_prompt = '\\nQ: '\n",
    "_answer_prompt = '\\nA: '\n",
    "    \n",
    "def get_text_up_to_question_number(text, number):\n",
    "    pos = text.find(_answer_prompt)\n",
    "    for _ in range(number):\n",
    "        pos = text.find(_answer_prompt, pos + 1)\n",
    "    return text[0:pos + 1]\n",
    "    \n",
    "def get_answers_number(text):\n",
    "    return text.count(_answer_prompt)\n",
    "\n",
    "def get_answer_number(text, number):\n",
    "    pos = text.find(_answer_prompt)\n",
    "    for _ in range(number):\n",
    "        pos = text.find(_answer_prompt, pos + 1)\n",
    "    end = text.find('\\n', pos + len(_answer_prompt))\n",
    "    return text[pos + len(_answer_prompt):end]\n",
    "\n",
    "def get_question_number(text, number):\n",
    "    pos = text.find(_question_prompt)\n",
    "    for _ in range(number):\n",
    "        pos = text.find(_question_prompt, pos + 1)\n",
    "    end = text.find('\\n', pos + len(_question_prompt))\n",
    "    return text[pos + len(_question_prompt):end]\n",
    "\n",
    "def get_all_answers(dev_dict, dev_index):\n",
    "    answers = [[item['input_text'] for item in dev_dict['data'][dev_index]['answers']]]\n",
    "    answers += [[item['input_text'] for item in dev_dict['data'][dev_index]['additional_answers'][str(index)]] for index in range(3)]\n",
    "    return [list(set([answers[j][i] for j in range(len(answers))])) for i in range(len(answers[0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39651446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_data_item(item, max_num_questions=0, question_number=-1, last_question=True):\n",
    "    text = 'In the text below two people are discussing a story.\\n\\n'\n",
    "    text += 'Story:\\n' + item['story'] + '\\n\\n'\n",
    "    text += 'Discussion:\\n'\n",
    "    text += '\\n'.join(['Q: ' + q['input_text'] \n",
    "                       + '\\nA: ' + a['input_text'] \n",
    "                       for q, a in zip(item['questions'][max(0,question_number-max_num_questions):question_number+1], \n",
    "                                       item['answers'][max(0,question_number-max_num_questions):question_number+1]) \n",
    "                      ])\n",
    "    if not last_question:\n",
    "        text = '\\n'.join(text.split('\\n')[:-1]) + '\\n'\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7c0b24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_multiple_answers(model, prompt, num_replicas=5):\n",
    "    model.train()\n",
    "    tokens = tokenizer.encode(prompt, return_tensors='pt')\n",
    "    _length = 50\n",
    "    tokens_length = tokens.shape[1]\n",
    "    if tokens_length + _length > 1024:\n",
    "        return ''\n",
    "    \n",
    "    outputs = []\n",
    "    for _ in range(num_replicas):\n",
    "        output = model.generate(\n",
    "             tokens.cuda(),\n",
    "             max_length=tokens_length + _length,\n",
    "             pad_token_id=50256\n",
    "        )\n",
    "        output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        offset = len(prompt)\n",
    "        start = offset + 1\n",
    "        end = output.find('\\n', start)\n",
    "        outputs.append(output[start:end].split(':')[-1].strip())\n",
    "        \n",
    "    return list(set(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32990b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_first_answer(model, prompt):\n",
    "    model.eval()\n",
    "    tokens = tokenizer.encode(prompt, return_tensors='pt')\n",
    "    _length = 50\n",
    "    tokens_length = tokens.shape[1]\n",
    "    if tokens_length + _length > 1024:\n",
    "        return ''\n",
    "    \n",
    "    output = model.generate(\n",
    "             tokens.cuda(),\n",
    "             max_length=tokens_length + _length,\n",
    "             pad_token_id=50256\n",
    "    )\n",
    "    output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    offset = len(prompt)\n",
    "    start = offset + 1\n",
    "    end = output.find('\\n', start)\n",
    "    return output[start:end].split(':')[-1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba651de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "model.cuda()\n",
    "checkpoint = torch.load('save_small' + str(6))\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56a34f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dict = json.load(open('../data/coqa-dev-v1.0.json', encoding='utf8'))\n",
    "dev_list = json.load(open('../data/qa_dev_list.json', encoding='utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a0dbdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_data_item(item, max_num_questions=0, question_number=-1, last_question=True):\n",
    "    text = 'In the text below two people are discussing a story.\\n\\n'\n",
    "    text += 'Story:\\n' + item['story'] + '\\n\\n'\n",
    "    text += 'Discussion:\\n'\n",
    "    text += '\\n'.join(['Q: ' + q['input_text'] \n",
    "                       + '\\nA: ' + a['input_text'] \n",
    "                       for q, a in zip(item['questions'][max(0,question_number-max_num_questions):question_number+1], \n",
    "                                       item['answers'][max(0,question_number-max_num_questions):question_number+1]) \n",
    "                      ])\n",
    "    if not last_question:\n",
    "        text = '\\n'.join(text.split('\\n')[:-1]) + '\\n'\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81d06c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=0\n",
    "number = 1\n",
    "small_text = get_text_from_data_item(dev_dict['data'][doc], \n",
    "                                     max_num_questions=5, \n",
    "                                     question_number=number,\n",
    "                                     last_question=False)\n",
    "first_answer = generate_first_answer(model, small_text)\n",
    "answers = generate_multiple_answers(model, small_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "efbf978e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_description_from_data_item(item):\n",
    "    return item['story']\n",
    "\n",
    "def get_dialogue_from_data_item(item, max_num_questions=0, question_number=-1, last_question=True):\n",
    "    text = ''\n",
    "    text += ' '.join([q['input_text'] + ' ' + a['input_text'] + '.'\n",
    "                       for q, a in zip(item['questions'][max(0,question_number-max_num_questions):question_number+1], \n",
    "                                       item['answers'][max(0,question_number-max_num_questions):question_number+1]) \n",
    "                      ])\n",
    "    if not last_question:\n",
    "        text = '?'.join(text.split('?')[:-1]) + '?'\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6baad863",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_claim_from_description_and_dialogue(description, dialogue):\n",
    "    if dialogue[-1] == '.':\n",
    "        dialogue = dialogue[:-1]    \n",
    "    text = 'Evidence:\\n'\n",
    "    text += description.replace('\\n\\n', '\\n') + '\\n\\n'\n",
    "    text += 'Claim:\\n'\n",
    "    text += dialogue + '\\n\\n'\n",
    "    text += 'The evidence supports the claim:\\n'\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "055b0761",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_answer(description, dialogue, first_answer, answers):\n",
    "    best_perplexity = 1e6\n",
    "    \n",
    "    #current_dialogue = dialogue + ' ' + first_answer\n",
    "    #text = create_claim_from_description_and_dialogue(description, current_dialogue)\n",
    "    #y_or_n, perplexity = generate_answer(fact_checking_model, text)\n",
    "    #if y_or_n == 'Y':\n",
    "    #    return first_answer, best_perplexity\n",
    "    \n",
    "    best_answer = ''\n",
    "    for answer in answers:\n",
    "        current_dialogue = dialogue + ' ' + answer\n",
    "        text = create_claim_from_description_and_dialogue(description, current_dialogue)\n",
    "        y_or_n, perplexity = generate_answer(fact_checking_model, text)\n",
    "        if perplexity < best_perplexity and y_or_n == 'Y':\n",
    "            best_perplexity = perplexity\n",
    "            best_answer = answer\n",
    "#    if not best_answer:\n",
    "#        best_perplexity = 0\n",
    "#        for answer in answers:\n",
    "#            current_dialogue = dialogue + ' ' + answer\n",
    "#            text = create_claim_from_description_and_dialogue(description, current_dialogue)\n",
    "#            y_or_n, perplexity = generate_answer(fact_checking_model, text)\n",
    "#            if perplexity > best_perplexity and y_or_n == 'N':\n",
    "#                best_perplexity = perplexity\n",
    "#                best_answer = answer            \n",
    "    if not best_answer:\n",
    "        best_answer = first_answer\n",
    "    return best_answer, best_perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa7cc50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = 0\n",
    "number = 6\n",
    "small_text = get_text_from_data_item(dev_dict['data'][doc], \n",
    "                                     max_num_questions=5, \n",
    "                                     question_number=number,\n",
    "                                     last_question=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7bdf939f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['white', 'White', 'orange']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('orange', 3.2131409645080566)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = 0\n",
    "number = 0\n",
    "description = get_description_from_data_item(dev_dict['data'][doc])\n",
    "small_text = get_text_from_data_item(dev_dict['data'][doc], \n",
    "                                     max_num_questions=5, \n",
    "                                     question_number=number,\n",
    "                                     last_question=False)\n",
    "first_answer = generate_first_answer(model, small_text)\n",
    "answers = generate_multiple_answers(model, small_text)\n",
    "dialogue = get_dialogue_from_data_item(dev_dict['data'][doc],\n",
    "                                       max_num_questions=5, \n",
    "                                       question_number=number,\n",
    "                                       last_question=False)\n",
    "print(answers)\n",
    "select_answer(description, dialogue, first_answer, answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a370e942",
   "metadata": {},
   "source": [
    "# Computing accuracy after fact checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d188c147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_original_accuracy_of_model(model):\n",
    "    total_number_of_questions = 0\n",
    "    correct_answers = 0\n",
    "    wrong_predictions = []\n",
    "\n",
    "    false_positives = []\n",
    "    dlist = dev_list[:10]\n",
    "    for index, text in tqdm(enumerate(dlist), total=len(dlist)):\n",
    "        total_questions = get_answers_number(text)\n",
    "        all_answers = get_all_answers(dev_dict, index)\n",
    "        for number in range(total_questions):\n",
    "            small_text = get_text_from_data_item(dev_dict['data'][index], \n",
    "                                                 max_num_questions=5,\n",
    "                                                 question_number=number,\n",
    "                                                 last_question=False)\n",
    "            #description = get_description_from_data_item(dev_dict['data'][index])\n",
    "            #dialogue = get_dialogue_from_data_item(dev_dict['data'][index],\n",
    "            #                           max_num_questions=5, \n",
    "            #                           question_number=number,\n",
    "            #                           last_question=False)\n",
    "            first_answer = generate_first_answer(model, small_text)\n",
    "            #answers = generate_multiple_answers(model, small_text)\n",
    "            prediction, _ = select_answer(description, dialogue, first_answer, [])\n",
    "            if not prediction:\n",
    "                print('NO PREDICTION!!')\n",
    "                continue\n",
    "            prediction = prediction.replace('.', '').replace('\"', '')\n",
    "            it_was_answered = False\n",
    "            for label in all_answers[number]:\n",
    "                label = label.replace('.', '').replace('\"', '')\n",
    "\n",
    "                if prediction.lower() != 'unknown' and label.lower() == 'unknown':\n",
    "                    false_positives.append(prediction)\n",
    "                \n",
    "                if prediction.lower() == label.lower():\n",
    "                    correct_answers += 1\n",
    "                    it_was_answered = True\n",
    "                    break\n",
    "                elif prediction.lower() in label.lower():\n",
    "                    correct_answers += 1\n",
    "                    it_was_answered = True\n",
    "                    break\n",
    "                elif label.lower() in prediction.lower():\n",
    "                    correct_answers += 1\n",
    "                    it_was_answered = True\n",
    "                    break\n",
    "                else:\n",
    "                    wrong_predictions.append({'label': label, 'prediction': prediction})\n",
    "            total_number_of_questions += 1\n",
    "\n",
    "    return correct_answers/total_number_of_questions, wrong_predictions, false_positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "82fe9850",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy_of_model(model):\n",
    "    total_number_of_questions = 0\n",
    "    correct_answers = 0\n",
    "    wrong_predictions = []\n",
    "\n",
    "    false_positives = []\n",
    "    dlist = dev_list[:10]\n",
    "    for index, text in tqdm(enumerate(dlist), total=len(dlist)):\n",
    "        total_questions = get_answers_number(text)\n",
    "        all_answers = get_all_answers(dev_dict, index)\n",
    "        for number in range(total_questions):\n",
    "            small_text = get_text_from_data_item(dev_dict['data'][index], \n",
    "                                                 max_num_questions=5,\n",
    "                                                 question_number=number,\n",
    "                                                 last_question=False)\n",
    "            description = get_description_from_data_item(dev_dict['data'][index])\n",
    "            dialogue = get_dialogue_from_data_item(dev_dict['data'][index],\n",
    "                                       max_num_questions=5, \n",
    "                                       question_number=number,\n",
    "                                       last_question=False)\n",
    "            first_answer = generate_first_answer(model, small_text)\n",
    "            answers = generate_multiple_answers(model, small_text)\n",
    "            prediction, _ = select_answer(description, dialogue, first_answer, answers)\n",
    "            if not prediction:\n",
    "                print('NO PREDICTION!!')\n",
    "                continue\n",
    "            prediction = prediction.replace('.', '').replace('\"', '')\n",
    "            it_was_answered = False\n",
    "            for label in all_answers[number]:\n",
    "                label = label.replace('.', '').replace('\"', '')\n",
    "\n",
    "                if prediction.lower() != 'unknown' and label.lower() == 'unknown':\n",
    "                    false_positives.append(prediction)\n",
    "                \n",
    "                if prediction.lower() == label.lower():\n",
    "                    correct_answers += 1\n",
    "                    it_was_answered = True\n",
    "                    break\n",
    "                elif prediction.lower() in label.lower():\n",
    "                    correct_answers += 1\n",
    "                    it_was_answered = True\n",
    "                    break\n",
    "                elif label.lower() in prediction.lower():\n",
    "                    correct_answers += 1\n",
    "                    it_was_answered = True\n",
    "                    break\n",
    "                else:\n",
    "                    wrong_predictions.append({'label': label, 'prediction': prediction})\n",
    "            total_number_of_questions += 1\n",
    "\n",
    "    return correct_answers/total_number_of_questions, wrong_predictions, false_positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2676fc5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [06:42<00:00, 40.22s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6099290780141844,\n",
       " [{'label': 'with her mommy and 5 sisters',\n",
       "   'prediction': 'her mommy and 5 other sisters'},\n",
       "  {'label': 'paint herself like them', 'prediction': 'she painted herself'},\n",
       "  {'label': 'the farmer', 'prediction': \"Cotton's mommy's\"},\n",
       "  {'label': \"the old farmer's\", 'prediction': \"Cotton's mommy's\"},\n",
       "  {'label': \"the farmer's\", 'prediction': \"Cotton's mommy's\"},\n",
       "  {'label': 'started laughing', 'prediction': 'They laughed'},\n",
       "  {'label': 'they started laughing', 'prediction': 'They laughed'},\n",
       "  {'label': 'rubbed her face', 'prediction': 'They laughed'},\n",
       "  {'label': 'dropped her into a big bucket of water',\n",
       "   'prediction': 'a bucket of water'},\n",
       "  {'label': 'a big bucket of water', 'prediction': 'a bucket of water'},\n",
       "  {'label': 'into a big bucket of water', 'prediction': 'a bucket of water'},\n",
       "  {'label': 'No', 'prediction': 'yes'},\n",
       "  {'label': 'no', 'prediction': 'yes'},\n",
       "  {'label': 'the bottle', 'prediction': \"It looked like a bird's belly\"},\n",
       "  {'label': 'a bottle', 'prediction': \"It looked like a bird's belly\"},\n",
       "  {'label': 'Asta', 'prediction': 'Sharkie'},\n",
       "  {'label': 'a note', 'prediction': 'A bottle'},\n",
       "  {'label': 'No', 'prediction': 'Yes'},\n",
       "  {'label': 'no', 'prediction': 'Yes'},\n",
       "  {'label': \"They took the note to Asta's papa\",\n",
       "   'prediction': 'they took it to the bottom of the ocean'},\n",
       "  {'label': 'unknown',\n",
       "   'prediction': 'they took it to the bottom of the ocean'},\n",
       "  {'label': \"They took the note to Asta's papa\",\n",
       "   'prediction': 'they took it to the bottom of the ocean'},\n",
       "  {'label': 'unknown', 'prediction': 'yes'},\n",
       "  {'label': 'An elderly Chinese lady and a little boy',\n",
       "   'prediction': 'the elderly Chinese lady'},\n",
       "  {'label': 'a little boy', 'prediction': 'a paper carrier bag'},\n",
       "  {'label': 'yes', 'prediction': 'a paper carrier bag'},\n",
       "  {'label': 'Yes', 'prediction': 'a paper carrier bag'},\n",
       "  {'label': 'a little boy', 'prediction': 'A paper carrier bag'},\n",
       "  {'label': 'her daughter bought the house next door', 'prediction': 'Nicole'},\n",
       "  {'label': 'his neighbor', 'prediction': 'Nicole'},\n",
       "  {'label': 'she has decided the narrator needs more nutrients',\n",
       "   'prediction': 'to get nutrients'},\n",
       "  {'label': 'I am having heart surgery soon, so her mother has decided I need more nutrients',\n",
       "   'prediction': 'to get nutrients'},\n",
       "  {'label': 'has become an almost-daily practice',\n",
       "   'prediction': 'to get nutrients'},\n",
       "  {'label': 'needs more nutrients before heart surger',\n",
       "   'prediction': 'to get nutrients'},\n",
       "  {'label': 'an iPad',\n",
       "   'prediction': 'She pointed to the screen, which displayed a message from her daughter telling me that her mother wanted to know if the food was all right and whether it was too salty I am not used to iPads, so she indicated I should go wit'},\n",
       "  {'label': 'rice, vegetables and either chicken, meat or shrimp, sometimes with a kind of pancake',\n",
       "   'prediction': 'food'},\n",
       "  {'label': 'soup and a stainless-steel container with rice, vegetables and either chicken, meat or shrimp, sometimes with a kind of pancake',\n",
       "   'prediction': 'food'},\n",
       "  {'label': 'hot soup and a container with rice, vegetables and either chicken, meat or shrimp, sometimes with a kind of pancake',\n",
       "   'prediction': 'food'},\n",
       "  {'label': 'hot soup, rice, vegetables, chicken, meat, or shrimp, sometimes with a kind of pancake',\n",
       "   'prediction': 'food'},\n",
       "  {'label': 'I am now working on some more Chinese words',\n",
       "   'prediction': 'I point to the screen, which displayed a message from her daughter telling me that her mother wanted to know if the food was all right and whether it was too salty I was not used to iPads, so she indicated I should go wit'},\n",
       "  {'label': 'use the iPad',\n",
       "   'prediction': 'I point to the screen, which displayed a message from her daughter telling me that her mother wanted to know if the food was all right and whether it was too salty I was not used to iPads, so she indicated I should go wit'},\n",
       "  {'label': 'go with her to her house',\n",
       "   'prediction': 'I point to the screen, which displayed a message from her daughter telling me that her mother wanted to know if the food was all right and whether it was too salty I was not used to iPads, so she indicated I should go wit'},\n",
       "  {'label': 'Nicole',\n",
       "   'prediction': 'I point to the screen, which displayed a message from her daughter telling me that her mother wanted to know if the food was all right and whether it was too salty I was not used to iPads, so she indicated I should go wit'},\n",
       "  {'label': 'Dennis Farina',\n",
       "   'prediction': 'Law & Order, Miami Vice, Thief, and Miami Vice'},\n",
       "  {'label': 'he was an actor', 'prediction': 'Police officer'},\n",
       "  {'label': 'cop-turned-actor', 'prediction': 'Police officer'},\n",
       "  {'label': 'Actor', 'prediction': 'Police officer'},\n",
       "  {'label': 'he was a consultant', 'prediction': 'He was on Law & Order'},\n",
       "  {'label': 'he got into acting', 'prediction': 'He was on Law & Order'},\n",
       "  {'label': 'Farina was cast in a film',\n",
       "   'prediction': 'He was on Law & Order'},\n",
       "  {'label': 'got into acting', 'prediction': 'He was on Law & Order'},\n",
       "  {'label': 'He joined a TV show cast',\n",
       "   'prediction': 'he joined the cast of the long-running Law & Order'},\n",
       "  {'label': ', he joined the cast of Law & Order',\n",
       "   'prediction': 'he joined the cast of the long-running Law & Order'},\n",
       "  {'label': 'joined the cast of Law & Order',\n",
       "   'prediction': 'he joined the cast of the long-running Law & Order'},\n",
       "  {'label': 'he joined the cast of  Law & Order',\n",
       "   'prediction': 'he joined the cast of the long-running Law & Order'},\n",
       "  {'label': 'No', 'prediction': 'Yes'},\n",
       "  {'label': 'no', 'prediction': 'Yes'},\n",
       "  {'label': 'an expensive car', 'prediction': 'a expensive car'},\n",
       "  {'label': 'An expensive car', 'prediction': 'a expensive car'},\n",
       "  {'label': 'flashy clothes and an expensive car',\n",
       "   'prediction': 'a expensive car'},\n",
       "  {'label': 'flashy', 'prediction': 'They were very colorful'},\n",
       "  {'label': 'Flashy', 'prediction': 'They were very colorful'},\n",
       "  {'label': 'No', 'prediction': 'Yes'},\n",
       "  {'label': 'no', 'prediction': 'Yes'},\n",
       "  {'label': 'cop', 'prediction': 'Police officer'},\n",
       "  {'label': 'No', 'prediction': 'yes'},\n",
       "  {'label': 'no', 'prediction': 'yes'},\n",
       "  {'label': 'get cookies and milk', 'prediction': 'walk to the bus stop'},\n",
       "  {'label': \"go to Quentin's house\", 'prediction': 'walk to the bus stop'},\n",
       "  {'label': 'go in for cookies and milk',\n",
       "   'prediction': 'walk to the bus stop'},\n",
       "  {'label': 'they go in for cookies and milk',\n",
       "   'prediction': 'walk to the bus stop'},\n",
       "  {'label': 'right before bedtime', 'prediction': 'when she is done'},\n",
       "  {'label': 'right before bedtime', 'prediction': 'when she is done'},\n",
       "  {'label': 'before bedtime', 'prediction': 'when she is done'},\n",
       "  {'label': 'no answer', 'prediction': 'unknown'},\n",
       "  {'label': 'no one answered', 'prediction': 'unknown'},\n",
       "  {'label': 'No', 'prediction': 'Yes'},\n",
       "  {'label': 'no', 'prediction': 'Yes'},\n",
       "  {'label': 'she was upset', 'prediction': \"Quinton's mother\"},\n",
       "  {'label': 'that she was upset', 'prediction': \"Quinton's mother\"},\n",
       "  {'label': 'yes',\n",
       "   'prediction': 'that he was going to the dentist and would be at school'},\n",
       "  {'label': 'yes', 'prediction': 'at the bus stop'},\n",
       "  {'label': 'after lunch', 'prediction': 'at the bus stop'},\n",
       "  {'label': 'New York City', 'prediction': 'Staten Island'},\n",
       "  {'label': 'New York', 'prediction': 'New Jersey'},\n",
       "  {'label': 'New York', 'prediction': 'New Jersey'},\n",
       "  {'label': 'In the southwest of the city',\n",
       "   'prediction': 'in the US state of New York'},\n",
       "  {'label': 'the southernmost part of both the city and state of New York',\n",
       "   'prediction': 'in the US state of New York'},\n",
       "  {'label': 'southernmost part of both the city and state of New York',\n",
       "   'prediction': 'in the US state of New York'},\n",
       "  {'label': 'the Arthur Kill and the Kill Van Kull,',\n",
       "   'prediction': 'Conference House Park'},\n",
       "  {'label': 'Arthur Kill and the Kill Van Kull',\n",
       "   'prediction': 'Conference House Park'},\n",
       "  {'label': 'the Arthur Kill and the Kill Van Kull',\n",
       "   'prediction': 'Conference House Park'},\n",
       "  {'label': 'inhabitants feel neglected by the city government',\n",
       "   'prediction': 'residents feel neglected'},\n",
       "  {'label': 'because the inhabitants feel neglected by the city government',\n",
       "   'prediction': 'residents feel neglected'},\n",
       "  {'label': 'inhabitants who feel neglected by the city government',\n",
       "   'prediction': 'residents feel neglected'},\n",
       "  {'label': 'The North Shore', 'prediction': 'the East Shore'},\n",
       "  {'label': 'North Shore', 'prediction': 'the East Shore'},\n",
       "  {'label': 'Weather forecast', 'prediction': 'the weather'},\n",
       "  {'label': 'yes', 'prediction': 'No'},\n",
       "  {'label': 'Yes', 'prediction': 'No'},\n",
       "  {'label': 'A violent storm', 'prediction': 'A wind'},\n",
       "  {'label': 'Glass, wood, and plaster', 'prediction': 'A wind'},\n",
       "  {'label': 'Glass, wood, plaster, and maybe the washing machine',\n",
       "   'prediction': 'A wind'},\n",
       "  {'label': 'Eppes', 'prediction': 'RJ'},\n",
       "  {'label': \"his father's flashlight\", 'prediction': 'The wind'},\n",
       "  {'label': \"the light of his father's flashlight\", 'prediction': 'The wind'},\n",
       "  {'label': 'The flashlight', 'prediction': 'The wind'},\n",
       "  {'label': 'the suspect', 'prediction': 'FBI'},\n",
       "  {'label': 'Gary Giordano', 'prediction': 'FBI'},\n",
       "  {'label': 'Maryland', 'prediction': 'Gaithersburg'},\n",
       "  {'label': 'Montgomery County', 'prediction': 'Maryland'},\n",
       "  {'label': 'Gaithersburg', 'prediction': 'Maryland'},\n",
       "  {'label': 'Montgomery', 'prediction': 'Maryland'},\n",
       "  {'label': 'Maryland', 'prediction': 'Montgomery'},\n",
       "  {'label': 'suspect in the recent disappearance of an American woman',\n",
       "   'prediction': 'he is being held in an Aruban jail'},\n",
       "  {'label': 'he is the suspect in the disappearance of an American woman',\n",
       "   'prediction': 'he is being held in an Aruban jail'},\n",
       "  {'label': 'he is a suspect in the recent disappearance of an American woman',\n",
       "   'prediction': 'he is being held in an Aruban jail'},\n",
       "  {'label': '15', 'prediction': '40 pm'},\n",
       "  {'label': 'About 15', 'prediction': '40 pm'},\n",
       "  {'label': 'Solicitor General', 'prediction': 'Philip Celestini'},\n",
       "  {'label': 'Aruban Solicitor General Taco Stein',\n",
       "   'prediction': 'Philip Celestini'},\n",
       "  {'label': 'Taco Stein', 'prediction': 'Philip Celestini'},\n",
       "  {'label': 'near baby beach', 'prediction': 'in the Caribbean island'},\n",
       "  {'label': 'ast seen near Baby Beach',\n",
       "   'prediction': 'in the Caribbean island'},\n",
       "  {'label': 'near Baby Beach', 'prediction': 'in the Caribbean island'},\n",
       "  {'label': 'snorkeling', 'prediction': 'swimming'},\n",
       "  {'label': 'Giordano', 'prediction': 'Gardner'},\n",
       "  {'label': '50-year-old', 'prediction': '50-years-old'},\n",
       "  {'label': '2, Giordano told authorities that he had been snorkeling with Gardner',\n",
       "   'prediction': '50-year-old'},\n",
       "  {'label': 'Two', 'prediction': '50-year-old'},\n",
       "  {'label': 'Great Britain', 'prediction': 'India'},\n",
       "  {'label': 'steam it',\n",
       "   'prediction': 'it lost nearly all of its healthy qualities'},\n",
       "  {'label': 'They steam it',\n",
       "   'prediction': 'it lost nearly all of its healthy qualities'},\n",
       "  {'label': 'Steam it',\n",
       "   'prediction': 'it lost nearly all of its healthy qualities'},\n",
       "  {'label': 'prune it',\n",
       "   'prediction': 'it lost nearly all of its healthy qualities'},\n",
       "  {'label': 'By accident',\n",
       "   'prediction': 'steamed right after the leaves were picked'},\n",
       "  {'label': 'Leaves fell into the hot water',\n",
       "   'prediction': 'steamed right after the leaves were picked'},\n",
       "  {'label': 'Leaves from a wild tea tree fell into a hot water pot',\n",
       "   'prediction': 'steamed right after the leaves were picked'},\n",
       "  {'label': 'by accident',\n",
       "   'prediction': 'steamed right after the leaves were picked'},\n",
       "  {'label': 'unknown', 'prediction': 'bad digestion'},\n",
       "  {'label': 'bloody', 'prediction': 'Sprawled over a patch of sand and grass'},\n",
       "  {'label': 'propped up, back to back',\n",
       "   'prediction': 'two US soldiers kneeling by a bloody body'},\n",
       "  {'label': 'what appears to be two bodies propped up,',\n",
       "   'prediction': 'two US soldiers kneeling by a bloody body'},\n",
       "  {'label': 'two bodies propped up',\n",
       "   'prediction': 'two US soldiers kneeling by a bloody body'},\n",
       "  {'label': 'in front of a military vehicle', 'prediction': 'a post'},\n",
       "  {'label': 'a military vehicle', 'prediction': 'a post'},\n",
       "  {'label': 'military vehicle', 'prediction': 'a post'}],\n",
       " ['they took it to the bottom of the ocean', 'yes', 'bad digestion'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_accuracy_of_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b915617",
   "metadata": {},
   "source": [
    "# Results\n",
    "Original accuracy: 0.7092198581560284\n",
    "\n",
    "using save_fever2: 0.7092198581560284\n",
    "\n",
    "using save_fever_with_qa_data_7: 0.7021276595744681"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05fd385",
   "metadata": {},
   "source": [
    "## Repeat the test with save number 7 <= there was an error with the evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c87271e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dispatcher",
   "language": "python",
   "name": "dispatcher"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
