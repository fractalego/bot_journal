{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d041322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e8380e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d10144a",
   "metadata": {},
   "source": [
    "# Question Answering part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7c0b24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_multiple_answers(model, prompt, num_replicas=25):\n",
    "    model.train()\n",
    "    outputs = []\n",
    "    with torch.no_grad():\n",
    "        tokens = tokenizer.encode(prompt, return_tensors='pt')\n",
    "        tokens = tokens.repeat(num_replicas,1)\n",
    "        _length = 50\n",
    "        tokens_length = tokens.shape[1]\n",
    "        if tokens_length + _length > 1024:\n",
    "            return ''\n",
    "\n",
    "        \n",
    "        output = model.generate(\n",
    "             tokens.cuda(),\n",
    "             max_length=tokens_length + _length,\n",
    "             pad_token_id=50256\n",
    "        )\n",
    "        for index in range(num_replicas):\n",
    "            text = tokenizer.decode(output[index, :], skip_special_tokens=True)\n",
    "            offset = len(prompt)\n",
    "            start = offset + 1\n",
    "            end = text.find('\\n', start)\n",
    "            outputs.append(text[start:end].split(':')[-1].strip())\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5086df2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config = GPT2Config(attn_pdrop=0.1, resid_pdrop=0.1, embd_pdrop=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba651de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPT2LMHeadModel(config).from_pretrained('gpt2')\n",
    "model.cuda()\n",
    "checkpoint = torch.load('save_small' + str(6))\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70060e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "sentence_model = SentenceTransformer('msmarco-distilbert-base-v3')\n",
    "sentence_model = sentence_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56a34f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dict = json.load(open('../data/coqa-dev-v1.0.json', encoding='utf8'))\n",
    "dev_list = json.load(open('../data/qa_dev_list.json', encoding='utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db18bdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_from_text(text):\n",
    "    outputs = sentence_model.encode(text)\n",
    "    return outputs\n",
    "\n",
    "def group_similar_answers_and_get_scores(answers):\n",
    "    answers_dict = {}\n",
    "    threshold = 0.7\n",
    "    embeddings = get_embeddings_from_text(answers)\n",
    "    embeddings = np.array([e/np.linalg.norm(e) for e in embeddings])\n",
    "    similarity_matrix = np.matmul(embeddings, embeddings.transpose())\n",
    "    superseded = set()\n",
    "    superseded_from = {}\n",
    "    for i in range(len(answers)):\n",
    "        for j in range(len(answers)):\n",
    "            if i > j:\n",
    "                continue\n",
    "            if i != j and answers[i] == answers[j]:\n",
    "                continue\n",
    "            if similarity_matrix[i][j] > threshold :\n",
    "                answers_dict.setdefault(i, 0)\n",
    "                answers_dict[i] += 1\n",
    "                if i != j:\n",
    "                    superseded.add(j)\n",
    "                    superseded_from.setdefault(i, [])\n",
    "                    superseded_from[i].append(j)\n",
    "\n",
    "    answers_and_scores = [(index, score/len(answers))\n",
    "                          for index, score in answers_dict.items() \n",
    "                          if index not in superseded]\n",
    "    \n",
    "    new_scores_dict = {}\n",
    "    total_score = sum(item[1] for item in answers_and_scores)\n",
    "    for answer_index, score in answers_and_scores:\n",
    "        answer_group = [answers[answer_index]]\n",
    "        if answer_index in superseded_from:\n",
    "            answer_group += [answers[i] for i in superseded_from[answer_index]]\n",
    "        answer_group = tuple(set(answer_group))\n",
    "        if answer_group in new_scores_dict:\n",
    "            new_scores_dict[answer_group] += score / total_score\n",
    "        else:\n",
    "            new_scores_dict[answer_group] = score / total_score\n",
    "    \n",
    "    \n",
    "    return sorted(list(new_scores_dict.items()), key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a0dbdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_data_item(item, max_num_questions=0, question_number=-1, last_question=True):\n",
    "    text = 'In the text below two people are discussing a story.\\n\\n'\n",
    "    text += 'Story:\\n' + item['story'] + '\\n\\n'\n",
    "    text += 'Discussion:\\n'\n",
    "    text += '\\n'.join(['Q: ' + q['input_text'] \n",
    "                       + '\\nA: ' + a['input_text'] \n",
    "                       for q, a in zip(item['questions'][max(0,question_number-max_num_questions):question_number+1], \n",
    "                                       item['answers'][max(0,question_number-max_num_questions):question_number+1]) \n",
    "                      ])\n",
    "    if not last_question:\n",
    "        text = '\\n'.join(text.split('\\n')[:-1]) + '\\n'\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81d06c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=0\n",
    "number = 0\n",
    "small_text = get_text_from_data_item(dev_dict['data'][doc], \n",
    "                                     max_num_questions=5, \n",
    "                                     question_number=number,\n",
    "                                     last_question=False)\n",
    "answers = generate_multiple_answers(model, small_text)\n",
    "answers = group_similar_answers_and_get_scores(answers)\n",
    "print(small_text)\n",
    "print(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8fd280",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "bot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
