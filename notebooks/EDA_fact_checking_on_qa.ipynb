{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e43aac28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adf11ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2d45915",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "fact_checking_model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "fact_checking_model.cuda()\n",
    "checkpoint = torch.load('save_fever2')\n",
    "fact_checking_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "_ = fact_checking_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e61a090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_up_to_question(text):\n",
    "    _claim_yn = 'The evidence supports the claim:\\n'\n",
    "    return text[:text.find(_claim_yn) + len(_claim_yn)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef5b4345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_from_text(text):\n",
    "    _claim_yn = 'The evidence supports the claim:\\n'\n",
    "    pos = text.find(_claim_yn) + len(_claim_yn)\n",
    "    return text[pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca1ac830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(model, text):\n",
    "    prompt = get_text_up_to_question(text)\n",
    "    tokens = tokenizer.encode(prompt, return_tensors='pt')\n",
    "    _length = 1\n",
    "    tokens_length = tokens.shape[1]\n",
    "    if tokens_length + _length >= 1024:\n",
    "        raise RuntimeError('Text is longer than 1024')\n",
    "    output = model.generate(\n",
    "             tokens.cuda(),\n",
    "             max_length=tokens_length + _length, \n",
    "             pad_token_id=50256\n",
    "    )\n",
    "    to_return = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    perplexity = float(model(output, labels=output)[0])\n",
    "    return get_answer_from_text(to_return), perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11228648",
   "metadata": {},
   "source": [
    "# Question Answering part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a387526c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_question_prompt = '\\nQ: '\n",
    "_answer_prompt = '\\nA: '\n",
    "    \n",
    "def get_text_up_to_question_number(text, number):\n",
    "    pos = text.find(_answer_prompt)\n",
    "    for _ in range(number):\n",
    "        pos = text.find(_answer_prompt, pos + 1)\n",
    "    return text[0:pos + 1]\n",
    "    \n",
    "def get_answers_number(text):\n",
    "    return text.count(_answer_prompt)\n",
    "\n",
    "def get_answer_number(text, number):\n",
    "    pos = text.find(_answer_prompt)\n",
    "    for _ in range(number):\n",
    "        pos = text.find(_answer_prompt, pos + 1)\n",
    "    end = text.find('\\n', pos + len(_answer_prompt))\n",
    "    return text[pos + len(_answer_prompt):end]\n",
    "\n",
    "def get_question_number(text, number):\n",
    "    pos = text.find(_question_prompt)\n",
    "    for _ in range(number):\n",
    "        pos = text.find(_question_prompt, pos + 1)\n",
    "    end = text.find('\\n', pos + len(_question_prompt))\n",
    "    return text[pos + len(_question_prompt):end]\n",
    "\n",
    "def get_all_answers(dev_dict, dev_index):\n",
    "    answers = [[item['input_text'] for item in dev_dict['data'][dev_index]['answers']]]\n",
    "    return [list(set([answers[j][i] for j in range(len(answers))])) for i in range(len(answers[0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6e96c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_data_item(item, max_num_questions=0, question_number=-1, last_question=True):\n",
    "    text = 'In the text below two people are discussing a story.\\n\\n'\n",
    "    text += 'Story:\\n' + item['story'] + '\\n\\n'\n",
    "    text += 'Discussion:\\n'\n",
    "    text += '\\n'.join(['Q: ' + q['input_text'] \n",
    "                       + '\\nA: ' + a['input_text'] \n",
    "                       for q, a in zip(item['questions'][max(0,question_number-max_num_questions):question_number+1], \n",
    "                                       item['answers'][max(0,question_number-max_num_questions):question_number+1]) \n",
    "                      ])\n",
    "    if not last_question:\n",
    "        text = '\\n'.join(text.split('\\n')[:-1]) + '\\n'\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54c90911",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = json.load(open('../data/coqa-train-v1.0.json', encoding='utf8'))\n",
    "train_list = json.load(open('../data/qa_train_list.json', encoding='utf8'))\n",
    "dev_dict = json.load(open('../data/coqa-dev-v1.0.json', encoding='utf8'))\n",
    "dev_list = json.load(open('../data/qa_dev_list.json', encoding='utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab274b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_data_item(item, max_num_questions=0, question_number=-1, last_question=True):\n",
    "    text = 'In the text below two people are discussing a story.\\n\\n'\n",
    "    text += 'Story:\\n' + item['story'] + '\\n\\n'\n",
    "    text += 'Discussion:\\n'\n",
    "    text += '\\n'.join(['Q: ' + q['input_text'] \n",
    "                       + '\\nA: ' + a['input_text'] \n",
    "                       for q, a in zip(item['questions'][max(0,question_number-max_num_questions):question_number+1], \n",
    "                                       item['answers'][max(0,question_number-max_num_questions):question_number+1]) \n",
    "                      ])\n",
    "    if not last_question:\n",
    "        text = '\\n'.join(text.split('\\n')[:-1]) + '\\n'\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c35f97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_description_from_data_item(item):\n",
    "    return item['story']\n",
    "\n",
    "def get_dialogue_from_data_item(item, max_num_questions=0, question_number=-1, last_question=True):\n",
    "    text = ''\n",
    "    text += ' '.join([q['input_text'] + ' ' + a['input_text'] + '.'\n",
    "                       for q, a in zip(item['questions'][max(0,question_number-max_num_questions):question_number+1], \n",
    "                                       item['answers'][max(0,question_number-max_num_questions):question_number+1]) \n",
    "                      ])\n",
    "    if not last_question:\n",
    "        text = '?'.join(text.split('?')[:-1]) + '?'\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10a39d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_claim_from_description_and_dialogue(description, dialogue):\n",
    "    if dialogue[-1] == '.':\n",
    "        dialogue = dialogue[:-1]\n",
    "    text = 'Evidence:\\n'\n",
    "    text += description.replace('\\n\\n', '\\n') + '\\n\\n'\n",
    "    text += 'Claim:\\n'\n",
    "    text += dialogue + '\\n\\n'\n",
    "    text += 'The evidence supports the claim:\\n'\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f077e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positive_list_of_claims():\n",
    "    claims = []\n",
    "    \n",
    "    total_number_of_questions = 0\n",
    "    correct_answers = 0\n",
    "    wrong_predictions = []\n",
    "    false_positives = []\n",
    "    dlist = train_list\n",
    "    for index, text in tqdm(enumerate(dlist), total=len(dlist)):\n",
    "        total_questions = get_answers_number(text)\n",
    "        all_answers = get_all_answers(train_dict, index)\n",
    "        for number in range(total_questions):\n",
    "            small_text = get_text_from_data_item(train_dict['data'][index], \n",
    "                                                 max_num_questions=5,\n",
    "                                                 question_number=number,\n",
    "                                                 last_question=False)\n",
    "            description = get_description_from_data_item(train_dict['data'][index])\n",
    "            dialogue = get_dialogue_from_data_item(train_dict['data'][index],\n",
    "                                       max_num_questions=5, \n",
    "                                       question_number=number,\n",
    "                                       last_question=True)\n",
    "            \n",
    "            last_answer = dialogue.split('?')[-1].strip().lower()\n",
    "            if stripped_answer(last_answer) not in ['yes', 'no']:\n",
    "                continue\n",
    "        \n",
    "            claims.append(create_claim_from_description_and_dialogue(description, dialogue) + 'Y')\n",
    "    return claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7739c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "model.cuda()\n",
    "checkpoint = torch.load('save_small' + str(1))\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "269d3d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_multiple_answers(model, prompt, num_replicas=2):\n",
    "    tokens = tokenizer.encode(prompt, return_tensors='pt')\n",
    "    _length = 50\n",
    "    tokens_length = tokens.shape[1]\n",
    "    if tokens_length + _length > 1024:\n",
    "        return ''\n",
    "    \n",
    "    outputs = []\n",
    "    for _ in range(num_replicas):\n",
    "        output = model.generate(\n",
    "             tokens.cuda(),\n",
    "             max_length=tokens_length + _length,\n",
    "             pad_token_id=50256\n",
    "        )\n",
    "        output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        offset = len(prompt)\n",
    "        start = offset + 1\n",
    "        end = output.find('\\n', start)\n",
    "        outputs.append(output[start:end].split(':')[-1].strip())\n",
    "        \n",
    "    return list(set(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8f73f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stripped_answer(text):\n",
    "    return text.lower().strip().replace('.', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b59d9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answers_are_consistent(lhs, rhs):\n",
    "    prediction = stripped_answer(lhs)\n",
    "    label = stripped_answer(rhs)\n",
    "    if prediction.lower() == label.lower():\n",
    "        return True\n",
    "    elif prediction.lower() in label.lower():\n",
    "        return True\n",
    "    elif label.lower() in prediction.lower():\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "546ff0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "def get_negative_list_of_claims():\n",
    "    claims = []\n",
    "    \n",
    "    total_number_of_questions = 0\n",
    "    correct_answers = 0\n",
    "    wrong_predictions = []\n",
    "\n",
    "    false_positives = []\n",
    "    dlist = train_list\n",
    "    random.shuffle(dlist)\n",
    "    for index, text in tqdm(enumerate(dlist), total=len(dlist)):\n",
    "        total_questions = get_answers_number(text)\n",
    "        all_answers = get_all_answers(train_dict, index)\n",
    "        for number in range(total_questions):\n",
    "            small_text = get_text_from_data_item(train_dict['data'][index],\n",
    "                                                 max_num_questions=5,\n",
    "                                                 question_number=number,\n",
    "                                                 last_question=False)\n",
    "            description = get_description_from_data_item(train_dict['data'][index])\n",
    "            dialogue = get_dialogue_from_data_item(train_dict['data'][index],\n",
    "                           max_num_questions=5, \n",
    "                           question_number=number,\n",
    "                           last_question=True)\n",
    "            last_answer = dialogue.split('?')[-1].strip().lower()\n",
    "            dialogue = '?'.join(dialogue.split('?')[:-1]) + '?'\n",
    "            wrong_answer = ''\n",
    "            if stripped_answer(last_answer) == 'yes':\n",
    "                wrong_answer = 'no'\n",
    "            elif stripped_answer(last_answer) == 'no':\n",
    "                wrong_answer = 'yes'\n",
    "\n",
    "            #else:\n",
    "            #    generated_answers = generate_multiple_answers(model, small_text)\n",
    "            #    for candidate in generated_answers:\n",
    "            #        if not answers_are_consistent(candidate, last_answer):\n",
    "            #            wrong_answer = candidate\n",
    "            #            break\n",
    "\n",
    "            if not wrong_answer:\n",
    "                continue\n",
    "            claims.append(create_claim_from_description_and_dialogue(description, dialogue + ' ' + wrong_answer) + 'N')\n",
    "    return claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "390355ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7199/7199 [00:01<00:00, 6272.77it/s]\n"
     ]
    }
   ],
   "source": [
    "positive_claims = get_positive_list_of_claims()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "241e5cc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7199/7199 [00:01<00:00, 6238.40it/s]\n"
     ]
    }
   ],
   "source": [
    "negative_claims = get_negative_list_of_claims()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c9689900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evidence:\n",
      "(CNN) -- The longest-running holiday special still has a very shiny nose. \n",
      "\"Rudolph the Red-Nosed Reindeer\" premiered on television December 6, 1964, and is now one of the holiday season's perennial favorites. The story of the reindeer who saves Christmas is beloved among children and adults alike. \n",
      "The Rankin-Bass animated film production company used Japanese puppets and stop motion to tell the tale, bolstered by a soundtrack featuring Burl Ives' rendition of the theme song. \n",
      "In the story, Santa's reindeer Donner and his wife have a son, Rudolph, who has the distinction of a nose that glows. He runs away after being made to feel an outcast and links up with an elf who dreams of becoming a dentist and an adventurer seeking silver and gold. \n",
      "After ending up on the Island of Misfit Toys and wandering for a while, Rudolph goes on to save his loved ones from the Abominable Snow Monster and guides Santa through a blizzard that threatens to ruin Christmas. \n",
      "In 2006, the New York Times reported that fans drove for miles to see the Rudolph and Santa Claus puppets at the Center for Puppetry Arts in Atlanta. The pair were thought to be the last of the surviving production puppets. They had been taken home by a production company employee and given to her children after filming was completed. \n",
      "\"In 2005, the nephew of the original rescuer found the puppets in a family attic and brought them to be appraised on the PBS series 'Antiques Roadshow,' \" the Times said. \"Created for about $5,000 each in 1964, they were valued at $8,000 to $10,000 for the pair. The family sold both figures to Kevin A. Kriess, the president of TimeandSpaceToys.com and a lifelong fan of the Rankin-Bass films.\" \n",
      "\n",
      "Claim:\n",
      "Does he save Christmas? yes. What Island does he travel to? the Island of Misfit Toys. Which company produced the movie? Rankin-Bass. When did it premiere? December 6, 1964. What methods were used in filming the movie? Japanese puppets and stop motion. Are all of the puppets still in existence? no\n",
      "\n",
      "The evidence supports the claim:\n",
      "Y\n"
     ]
    }
   ],
   "source": [
    "print(positive_claims[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96caf672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evidence:\n",
      "CHAPTER XXIV. THE INTERRUPTED MASS \n",
      "The morning of that Wednesday of Corpus Christi, fateful to all concerned in this chronicle, dawned misty and grey, and the air was chilled by the wind that blew from the sea. The chapel bell tinkled out its summons, and the garrison trooped faithfully to Mass. \n",
      "Presently came Monna Valentina, followed by her ladies, her pages, and lastly, Peppe, wearing under his thin mask of piety an air of eager anxiety and unrest. Valentina was very pale, and round her eyes there were dark circles that told of sleeplessness, and as she bowed her head in prayer, her ladies observed that tears were falling on the illuminated Mass-book over which she bent. And now came Fra Domenico from the sacristy in the white chasuble that the Church ordains for the Corpus Christi feast, followed by a page in a clerkly gown of black, and the Mass commenced. \n",
      "There were absent only from the gathering Gonzaga and Fortemani, besides a sentry and the three prisoners. Francesco and his two followers. \n",
      "Gonzaga had presented himself to Valentina with the plausible tale that, as the events of which Fanfulla's letter had given them knowledge might lead Gian Maria at any moment to desperate measures, it might be well that he should reinforce the single man-at-arms patrolling the walls. Valentina, little recking now whether the castle held or fell, and still less such trifles as Gonzaga's attendance at Mass, had assented without heeding the import of what he said. \n",
      "And so, his face drawn and his body quivering with the excitement of what he was about to do, Gonzaga had repaired to the ramparts so soon as he had seen them all safely into chapel. The sentinel was that same clerkly youth Aventano, who had read to the soldiers that letter Gian Maria had sent Gonzaga. This the courtier accepted as a good omen. If a man there was among the soldiery at Roccaleone with whom he deemed that he had an account to settle, that man was Aventano. \n",
      "\n",
      "Claim:\n",
      "Who arrived at the church? the garrison first. Who was followed by a clerk dressed in black? Fra. Domenico. Who was crying? Valentina. Who noticed it? her ladies. Did any others arrive with her? no\n",
      "\n",
      "The evidence supports the claim:\n",
      "N\n"
     ]
    }
   ],
   "source": [
    "print(negative_claims[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d02d0088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "split = 0.8\n",
    "all_list = positive_claims + negative_claims\n",
    "random.shuffle(all_list)\n",
    "train_list = all_list[:int(len(all_list) * split)]\n",
    "dev_list = all_list[int(len(all_list) * split):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba5d9072",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(train_list, open('../data/train_fc_with_qa.json', 'w'))\n",
    "json.dump(dev_list, open('../data/dev_fc_with_qa.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "865d224c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evidence:\n",
      "My summer hols wr CWOT. B4, we usd 2 go 2 NY 2C my bro, his GF & thr3:-@ kids FTF. ILNY, it's gr8. Can you understand this sentence? If you can't, don't feel too bad; neither could the middle school teacher in England who received this as homework. This is Netspeak: the language of computerized communication found on Internet or cell phones. To new comers, it can look like a completely foreign language. So, what is the translation of the sentence above? My summer holidays were a complete waste of time. Before, we used to go to New York to see my brother, his girlfriend, and their three screaming kids face to face. I love New York. It's great. School teachers and parents say this new form of writing is harming the English language. Increasing spelling and grammatical mistakes can be seen in students' writing. They fear the language could become corrupted . \"Everyone should just relax\", say linguists . They believe Netspeak is in fact more of a good thing. David Crystal, from the University of Wales, argues that Netspeak and Internet create a new language use and the almost lost art of diary writing, has been picked up again. Geoffrey Nurberg, from Stanford University, agrees. \"People get better at writing by writing,\" he says. \"kids who are now doing text messaging, e-mails, and instant messages will write at least as well as, and possibly better than their parents.\" Linguist James says, for centuries, it is believed without exception that young people are harming the language. And you can _ that when today's teenagers become tomorrow's parents. They too will think this way. James argues that languages do not and cannot become corrupted. They simply change to meet the new needs. However, Netspeakers do agree that it is important to teach young people how to speak and write standard English. Cynthia McVey says, \"I can understand Netspeak worries teachers and it's important that they get across to their pupils that text messaging is for fun, but learning to write proper English is a must for their future.\" Perhaps we should give teenagers a little more trust anyway. Erin, aged 12, says, \"I wouldn't use text language in my homework. Texting is just for fun. \"\n",
      "\n",
      "Claim:\n",
      "What is one reason they give? create a new language. Are there any other reasons? lost art of diary writing, has been picked up again. How does this affect writing? People get better at writing by writing. Will this process continue? yes. Do the experts think Netspeak should replace current writing entirely? No. Do young netspeakers agree? Yes\n",
      "\n",
      "The evidence supports the claim:\n",
      "Y\n"
     ]
    }
   ],
   "source": [
    "print(train_list[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74af6a20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dispatcher",
   "language": "python",
   "name": "dispatcher"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
